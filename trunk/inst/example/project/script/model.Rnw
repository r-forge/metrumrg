\input{settings.sty}
\usepackage{Sweave}
\SweaveOpts{keep.source=true}
\SweaveOpts{eps=false} 
\begin{document}
\vspace*{2cm}
\begin{center}
{\Large Modeling}\\
~\\
\today\\
~\\
Tim Bergsma\\
\end{center}
\newpage

\section{Purpose}
This script runs NONMEM models and diagnostics for sample phase1 data.
\section{Model Development}
\subsection{Set up for NONMEM run.}
<<model>>=
library(metrumrg)
#command <- '/opt/NONMEM/nm72/nmqual/autolog.pl'
cat.cov='SEX'
cont.cov=c('HEIGHT','WEIGHT','AGE')
par.list=c('CL','Q','KA','V','V2','V3')
eta.list=paste('ETA',1:10,sep='')
@
\subsection{Run NONMEM.}
<<run>>=
NONR72(
     run=1001:1005,
     #command=command,
     project='../nonmem',
     grid=FALSE,
     nice=TRUE,
     checkrunno=FALSE,
     cont.cov=cont.cov,
     cat.cov=cat.cov,
     par.list=par.list,
     eta.list=eta.list,
     plotfile='../nonmem/*/*.pdf',
     streams='../nonmem/ctl'
)
@
Covariance succeeded on model 1005.
We can make a quick run log using some simple tools. Table \ref{runlog}.
<<runlog>>=
log <- rlog(1001:1005,'../nonmem',tool='nm7',file=NULL)
head(log)
tail(log)
sapply(log,class)
log$tool <- NULL
unique(log$parameter)
log <- log[log$parameter %in% c('ofv','prob','cov','min'),]
log
with(log, constant(moment,within=parameter))#i.e., moment is non-informative here.
log <- data.frame(cast(log,run~parameter))
log <- shuffle(log,'prob','run')
log$ofv <- signif(as.numeric(as.character(log$ofv,6)))
@
<<runlog,results=tex,echo=FALSE>>=
writeLines(
  ltable(
    log,
    caption='Run Log',
    cap='Run Log',
	  label='runlog'
  )
)
@
\section{Predictive Check}
\subsection{Create a simulation control stream.}
Convert control stream to R object.
<<predict>>=
ctl <- read.nmctl('../nonmem/ctl/1005.ctl')
@
Strip comments and view.
<<strip>>=
ctl[] <- lapply(ctl,function(rec)sub(' *;.*','',rec))
ctl
@
Fix records of interest.
<<fix>>=
ctl$prob
ctl$prob <- sub('1005','1105',ctl$prob)
names(ctl)
names(ctl)[names(ctl)=='theta'] <- 'msfi'
ctl$msfi <- '=../1005/1005.msf'
ctl$omega <- NULL
ctl$sigma <- NULL
names(ctl)[names(ctl)=='estimation'] <- 'simulation'
ctl$simulation <- 'ONLYSIM (1968) SUBPROBLEMS=500'
ctl$cov <- NULL
ctl$table <- NULL
ctl$table <- NULL
ctl$table <- 'DV NOHEADER NOPRINT FILE=./1105.tab FORWARD NOAPPEND'
write.nmctl(ctl,'../nonmem/ctl/1105.ctl')
@
\subsection{Run the simulation.}
This run makes the predictions (simulations).
<<sim>>=
NONR72(
     run=1105,
     #command=command,
     project='../nonmem',
     grid=FALSE,
     nice=TRUE,
     diag=FALSE,
     streams='../nonmem/ctl'
)
@
\subsection{Recover and format the original dataset.}
Now we fetch the results and integrate them with the other data.
<<fetch>>=   
phase1 <- read.csv('../data/derived/phase1.csv',na.strings='.')
head(phase1)
phase1 <- phase1[is.na(phase1$C),c('SUBJ','TIME','DV')]
records <- nrow(phase1)
records
phase1 <- phase1[rep(1:records,500),]
nrow(phase1)
phase1$SIM <- rep(1:500,each=records)
#head(phase1,300)
with(phase1,DV[SIM==1 & SUBJ==12])
with(phase1,DV[SIM==2 & SUBJ==12])
@
\subsection{Recover and format the simulation results.}
<<preds>>=
pred <- scan('../nonmem/1105/1105.tab')
nrow(phase1)
length(pred)
@ 
\subsection{Combine the original data and the simulation data.}
<<combine>>=
phase1$PRED <- pred
head(phase1)
phase1 <- phase1[!is.na(phase1$DV),]
head(phase1)
@
\subsection{Plot predictive checks.}
\subsubsection{Aggregate data within subject.}
Since subjects may contribute differing numbers of observations, it may
be useful to look at predictions from a subject-centric perspective.
Therefore, we wish to calculate summary statistics for each subject, 
(observed and predicted) and then make obspred comparisons therewith.
<<subject>>=
head(phase1)
subject <- melt(phase1,measure.var=c('DV','PRED'))
head(subject)
@
We are going to aggregate each subject's DV and PRED values using cast().
cast() likes an aggregation function that returns a list.
We write one that grabs min med max for each subject, sim, and variable.
<<metrics>>=
metrics <- function(x)list(min=min(x), med=median(x), max=max(x))
@
Now we cast, ignoring time.
<<cast>>=
subject <- data.frame(cast(subject, SUBJ + SIM + variable ~ .,fun=metrics))
head(subject)
@
Note that regardless of SIM, DV (observed) is constant.

Now we melt the metrics.
<<metrics>>=
metr <- melt(subject,measure.var=c('min','med','max'),variable_name='metric')
head(metr)
metr$value <- reapply(
	metr$value,
	INDEX=metr[,c('SIM','variable','metric')],
	FUN=sort,
	na.last=FALSE
)
metr <- data.frame(cast(metr))
head(metr)
nrow(metr)
metr <- metr[!is.na(metr$DV),]#maybe no NA
nrow(metr)
@
We plot using lattice.
<<qq,fig=TRUE>>=
print(
	xyplot(
		PRED~DV|metric,
		metr,
		groups=SIM,
		scales=list(relation='free'),
		type='l',
		panel=function(...){
			panel.superpose(...)
			panel.abline(0,1,col='white',lwd=2)
		}
	)
)
@

For detail, we show one endpoint, tossing the outer 5 percent of values, and 
indicating quartiles.
<<qqdetail,fig=TRUE>>=
med <- metr[metr$metric=='med',]
med$metric <- NULL
head(med)
trim <- inner(med, id.var=c('SIM'),measure.var=c('PRED','DV'))
head(trim)
nrow(trim)
trim <- trim[!is.na(trim$DV),]
nrow(trim)
head(trim)
print(
	xyplot(
		PRED~DV,
		trim,
		groups=SIM,
		type='l',
		panel=function(x,y,...){
			panel.xyplot(x=x,y=y,...)
			panel.abline(0,1,col='white',lwd=2)
			panel.abline(
				v=quantile(x,probs=c(0.25,0.5,0.75)),
				col='grey',
				lty=2
			)
		}
	)
)
@

We also show densityplots of predictions at those quartiles.
<<qqdensity,fig=TRUE>>=
head(trim)
quantile(trim$DV)
molt <- melt(trim, id.var='SIM')
head(molt)
quart <- data.frame(cast(molt,SIM+variable~.,fun=quantile,probs=c(0.25,0.5,0.75)))
head(quart)
molt <- melt(quart,id.var='variable',measure.var=c('X25.','X50.','X75.'),variable_name='quartile')
head(molt)
levels(molt$quartile)
levels(molt$quartile) <- c('first quartile','second quartile','third quartile')
head(molt)
levels(molt$variable)
molt$variable <- factor(molt$variable,levels=c('PRED','DV'))
print(
	densityplot(
		~value|quartile,
		molt,
		groups=variable,
		layout=c(3,1),
		scales=list(relation='free'),
		aspect=1,
		panel=panel.superpose,
		panel.groups=function(x,...,group.number){
			if(group.number==1)panel.densityplot(x,...)
			if(group.number==2)panel.abline(v=unique(x),...)
		},
		auto.key=TRUE
	)
)
@
\section{Bootstrap Estimates of Parameter Uncertainty}
\subsection{Create directories.}
<<bootstrap>>=
getwd()
dir.create('../nonmem/1005.boot')
dir.create('../nonmem/1005.boot/data')
dir.create('../nonmem/1005.boot/ctl')
@
\subsection{Create replicate control streams.}
<<control>>=
t <- metaSub(
     clear(readLines('../nonmem/ctl/1005.ctl'),';.+',fixed=FALSE),
     names=1:300,
     pattern=c(
         '1005',
         '../../data/derived/phase1.csv',
         '$COV',
         '$TABLE'
     ),
     replacement=c(
         '*',
         '../data/*.csv',
         ';$COV',
         ';$TABLE'
    ),
    fixed=TRUE,
    out='../nonmem/1005.boot/ctl',
    suffix='.ctl'
 )
@
\subsection{Create replicate data sets by resampling original.}
<<resample>>=
 bootset <- read.csv('../data/derived/phase1.csv')
 r <- resample(
 	bootset,
 	names=1:300,
 	key='ID',
 	rekey=TRUE,
 	out='../nonmem/1005.boot/data',
 	stratify='SEX'
 )
@
\subsection{Run bootstrap models.}
<<boot>>=
NONR72(
     run=1:300,
     #command=command,
     project='../nonmem/1005.boot/',
     boot=TRUE,
     nice=TRUE,
     grid=TRUE,
     #concurrent=TRUE,
     streams='../nonmem/1005.boot/ctl'
)
nms <- paste('../nonmem/1005.boot/',1:300,'.boot/',1:300,'.log.xml',sep='')
while(!(all(file.exists(nms))))Sys.sleep(10)
boot <- rlog(
	run=1:300,
	project='../nonmem/1005.boot',
	boot=TRUE,
	append=FALSE,
	tool='nm7',
  file=NULL
)
write.csv(boot, '../nonmem/1005.bootlog.csv')
@
\section{File Disposition}
Predictive checks and bootstraps make huge files that need not be retained.
<<cleanup>>=
unlink('../nonmem/1105',recursive=TRUE)
unlink('../nonmem/1005.boot',recursive=TRUE)
@
\end{document}
