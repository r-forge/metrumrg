\input{settings.sty}
\usepackage{Sweave}
\SweaveOpts{keep.source=true}
\SweaveOpts{eps=false} 
\begin{document}
\vspace*{2cm}
\begin{center}
{\Large Modeling}\\
~\\
\today\\
~\\
Tim Bergsma\\
\end{center}
\newpage

\section{Purpose}
This script runs NONMEM models and diagnostics for sample phase1 data.
\section{Model Development}
\subsection{Set up for NONMEM run.}
<<model>>=
#Be sure to set directory to the script directory that contains this file.
library(metrumrg)
#command <- '/opt/NONMEM/nm72/nmqual/autolog.pl'
cat.cov='SEX'
cont.cov=c('HEIGHT','WEIGHT','AGE')
par.list=c('CL','Q','KA','V','V2','V3')
eta.list=paste('ETA',1:10,sep='')
@
\subsection{Run NONMEM.}
<<run>>=
NONR72(
     run=1001:1005,                       # 5 models, ctl pre-written
     #command=command,                    # this version will search for NONMEM
     project='../nonmem',                 # must specify, unless ctl in getwd()
     grid=TRUE,                           # set to FALSE for better error messaging (but slower)
     nice=TRUE,                           # don't delete subversioned directories
     checkrunno=FALSE,                    # TRUE auto-replaces conflicting run numbers 
     cont.cov=cont.cov,                   # see help for following
     cat.cov=cat.cov,
     par.list=par.list,
     eta.list=eta.list,
     grp='SEX',                           # separate diagnostic plots for each level of SEX
     grpnames=c('female','male'),         # use these instead of 0, 1, when plotting by SEX
     include.all=TRUE,                    # also show diagnostics with groups combined
     plotfile='../nonmem/*/*.pdf',        # use the run dir and run name for the plot file 
     streams='../nonmem/ctl'              # expect the control streams here, not locally
)
ready <- FALSE
while (!ready){
  state <- sapply(1001:1005,runstate,project='../nonmem')  # infer run progress from file presence/absence
  print(state)
  if(all(state=='done'))ready <- TRUE     #continue only when runs complete
  Sys.sleep(3)                            #wait three seconds and check again
}
@
Covariance succeeded on model 1005.
We can make a quick run log using some simple tools. Table \ref{runlog}.
<<runlog>>=
log <- rlog(1001:1005,'../nonmem',file=NULL) #don't want the 'wide' file, just the 'long' R object
head(log)
tail(log)
sapply(log,class)
log$tool <- NULL
unique(log$parameter)
log <- log[log$parameter %in% c('ofv','prob','cov','min'),]
log
with(log, constant(moment,within=parameter))#i.e., moment is non-informative here.
log <- data.frame(cast(log,run~parameter))
log <- shuffle(log,'prob','run')
log$ofv <- signif(as.numeric(as.character(log$ofv,6)))
@
<<runlog,results=tex,echo=FALSE>>=
writeLines(
  ltable(
    log,
    caption='Run Log',
    cap='Run Log',
	  label='runlog'
  )
)
@
\section{Predictive Check}
\subsection{Create a simulation control stream.}
Convert control stream to R object.
<<predict>>=
ctl <- read.nmctl('../nonmem/ctl/1005.ctl')
@
Strip comments and view.
<<strip>>=
ctl[] <- lapply(ctl,function(rec)sub(' *;.*','',rec))          # read control stream into a list
ctl                                                            # print it like text
@
Fix records of interest.
<<fix>>=
ctl$prob                                                       # problem statement
ctl$prob <- sub('1005','1105',ctl$prob)                        # substitute new run number
names(ctl)
names(ctl)[names(ctl)=='theta'] <- 'msfi'                      # replace theta with final msfi
ctl$msfi <- '=../1005/1005.msf'
ctl$omega <- NULL                                              # drop omega, sigma
ctl$sigma <- NULL
names(ctl)[names(ctl)=='estimation'] <- 'simulation'           # simulate instead of estimate
ctl$simulation <- 'ONLYSIM (1968) SUBPROBLEMS=500'             
ctl$cov <- NULL                                                # drop covariance step
ctl$table <- NULL                                              # replace multiple tables with one
ctl$table <- NULL
ctl$table <- 'DV NOHEADER NOPRINT FILE=./1105.tab FORWARD NOAPPEND' # only really need DV, save file space
write.nmctl(ctl,'../nonmem/ctl/1105.ctl')
@
\subsection{Run the simulation.}
This run makes the predictions (simulations).
<<sim>>=
NONR72(
     run=1105,
     #command=command,
     project='../nonmem',
     grid=TRUE,
     nice=TRUE,
     diag=FALSE,
     streams='../nonmem/ctl'
)
while (runstate(1105,project='../nonmem')!='done')Sys.sleep(5)
@
\subsection{Combine the original data and the simulation data.}
Now we fetch the results and integrate them with the other data.
<<fetch>>= 
x <- superset(
  run=1105,
  project='../nonmem',
  read.output=list(read.table,header=FALSE)
)
x <- x[,c('SUBJ','TIME','DV','V1','1105')]
read.nmctl('../nonmem/1105/1105.ctl')$simulation
x$SIM <- rep(1:500,each=nrow(x)/500)
colname(x) <- c(V1='PRED')
x <- x[x$`1105`==1,]
x$`1105` <- NULL
head(x)
nrow(x)
str(x)
x <- x[x$DV != '.',]
x$DV <- as.numeric(x$DV)
@
\subsection{Plot predictive checks.}
\subsubsection{Aggregate data within subject.}
Since subjects may contribute differing numbers of observations, it may
be useful to look at predictions from a subject-centric perspective.
Therefore, we wish to calculate summary statistics for each subject, 
(observed and predicted) and then make obspred comparisons therewith.
<<subject>>=
head(x)
subject <- melt(x,measure.var=c('DV','PRED'))
head(subject)
@
We are going to aggregate each subject's DV and PRED values using cast().
cast() likes an aggregation function that returns a list.
We write one that grabs min med max for each subject, sim, and variable.
<<metrics>>=
metrics <- function(x)list(min=min(x), med=median(x), max=max(x))
@
Now we cast, ignoring time.
<<cast>>=
subject <- data.frame(cast(subject, SUBJ + SIM + variable ~ .,fun=metrics))
head(subject)
@
Note that regardless of SIM, DV (observed) is constant.

Now we melt the metrics.
<<metrics>>=
metr <- melt(subject,measure.var=c('min','med','max'),variable_name='metric')
head(metr)
metr$value <- reapply(
	metr$value,
	INDEX=metr[,c('SIM','variable','metric')],
	FUN=sort,
	na.last=FALSE
)
metr <- data.frame(cast(metr))
head(metr)
nrow(metr)
metr <- metr[!is.na(metr$DV),]#maybe no NA
nrow(metr)
@
We plot using lattice.
<<qq,fig=TRUE>>=
print(
	xyplot(
		PRED~DV|metric,
		metr,
		groups=SIM,
		scales=list(relation='free'),
		type='l',
		panel=function(...){
			panel.superpose(...)
			panel.abline(0,1,col='white',lwd=2)
		}
	)
)
@

For detail, we show one endpoint, tossing the outer 5 percent of values, and 
indicating quartiles.
<<qqdetail,fig=TRUE>>=
med <- metr[metr$metric=='med',]
med$metric <- NULL
head(med)
trim <- inner(med, id.var=c('SIM'),measure.var=c('PRED','DV'))
head(trim)
nrow(trim)
trim <- trim[!is.na(trim$DV),]
nrow(trim)
head(trim)
print(
	xyplot(
		PRED~DV,
		trim,
		groups=SIM,
		type='l',
		panel=function(x,y,...){
			panel.xyplot(x=x,y=y,...)
			panel.abline(0,1,col='white',lwd=2)
			panel.abline(
				v=quantile(x,probs=c(0.25,0.5,0.75)),
				col='grey',
				lty=2
			)
		}
	)
)
@

We also show densityplots of predictions at those quartiles.
<<qqdensity,fig=TRUE>>=
head(trim)
quantile(trim$DV)
molt <- melt(trim, id.var='SIM')
head(molt)
quart <- data.frame(cast(molt,SIM+variable~.,fun=quantile,probs=c(0.25,0.5,0.75)))
head(quart)
molt <- melt(quart,id.var='variable',measure.var=c('X25.','X50.','X75.'),variable_name='quartile')
head(molt)
levels(molt$quartile)
levels(molt$quartile) <- c('first quartile','second quartile','third quartile')
head(molt)
levels(molt$variable)
molt$variable <- factor(molt$variable,levels=c('PRED','DV'))
print(
	densityplot(
		~value|quartile,
		molt,
		groups=variable,
		layout=c(3,1),
		scales=list(relation='free'),
		aspect=1,
		panel=panel.superpose,
		panel.groups=function(x,...,group.number){
			if(group.number==1)panel.densityplot(x,...)
			if(group.number==2)panel.abline(v=unique(x),...)
		},
		auto.key=TRUE
	)
)
@
\section{Bootstrap Estimates of Parameter Uncertainty}
\subsection{Create directories.}
<<bootstrap>>=
getwd()
dir.create('../nonmem/1005.boot')
dir.create('../nonmem/1005.boot/data')
dir.create('../nonmem/1005.boot/ctl')
@
\subsection{Create replicate control streams.}
<<control>>=
ctl <- clear(readLines('../nonmem/ctl/1005.ctl'),';.+',fixed=FALSE)
ctl <- read.nmctl('../nonmem/1005/1005.ctl')
ctl <- as.nmctl(ctl)
names(ctl)
ctl$cov <- NULL
ctl$table <- NULL
ctl$table <- NULL
ctl$prob
ctl$data
invisible(
  lapply(
    1:300,
    function(i,ctl){
      ctl$prob <- sub('1005',i,ctl$prob)
      ctl$data <- sub(
        '../../data/derived/phase1.csv',
        sub('\\*',i,'../data/*.csv'),
        ctl$data
      )
      write.nmctl(ctl,file=glue('../nonmem/1005.boot/ctl/',i,'.ctl'))
    },
    ctl=ctl
  )
)
@
\subsection{Create replicate data sets by resampling original.}
<<resample>>=
 bootset <- read.csv('../data/derived/phase1.csv')
 r <- resample(
 	bootset,
 	names=1:300,
 	key='ID',
 	rekey=TRUE,
 	out='../nonmem/1005.boot/data',
 	stratify='SEX'
 )
@
\subsection{Run bootstrap models.}
<<boot>>=
NONR72(
     run=1:300,
     boot=TRUE,
     concurrent=FALSE,
     project='../nonmem/1005.boot',
     streams='../nonmem/1005.boot/ctl'
)
length(dir('../nonmem/1005.boot',recursive = TRUE))
system('qstat -f')
ready <- FALSE
while (!ready){
  state <- sapply(1:300,runstate,project='../nonmem/1005.boot')  # infer run progress from file presence/absence
  print(table(state))
  if(all(state=='done'))ready <- TRUE     #continue only when runs complete
  Sys.sleep(10)                            #wait 10 seconds and check again
}
boot <- rlog(
	run=1:300,
	project='../nonmem/1005.boot',
	boot=TRUE,
	append=FALSE,
	tool='nm7',
  file=NULL
)
write.csv(boot, '../nonmem/1005.bootlog.csv')
@
\section{File Disposition}
Predictive checks and bootstraps make huge files that need not be retained.
<<cleanup>>=
unlink('../nonmem/1105',recursive=TRUE)
unlink('../nonmem/1005.boot',recursive=TRUE)
@
\end{document}
